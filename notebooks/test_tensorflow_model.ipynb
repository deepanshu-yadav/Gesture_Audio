{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deepanshu/anaconda3/envs/tf_14/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/deepanshu/anaconda3/envs/tf_14/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/deepanshu/anaconda3/envs/tf_14/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/deepanshu/anaconda3/envs/tf_14/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/deepanshu/anaconda3/envs/tf_14/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/deepanshu/anaconda3/envs/tf_14/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/deepanshu/anaconda3/envs/tf_14/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/deepanshu/anaconda3/envs/tf_14/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/deepanshu/anaconda3/envs/tf_14/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/deepanshu/anaconda3/envs/tf_14/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/deepanshu/anaconda3/envs/tf_14/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/deepanshu/anaconda3/envs/tf_14/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n",
      "WARNING:tensorflow:From /home/deepanshu/anaconda3/envs/tf_14/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f2ab3d27410>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Jun 20 20:40:23 2019\n",
    "@author: santonas\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#%%\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from time import sleep\n",
    "\n",
    "#%%\n",
    "targets_dict = {\n",
    "    0:\"Thumb Down\",\n",
    "    1:\"Stop Sign\",\n",
    "    2:\"Sliding Two Fingers Left\",\n",
    "    3:\"Sliding Two Fingers Right\",\n",
    "    4:\"No gesture\",\n",
    "    5:\"Thumb Up\"\n",
    "    }\n",
    "#%%\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "#%%\n",
    "def normaliz_data(np_data):\n",
    "    # Normalisation\n",
    "    scaler = StandardScaler()\n",
    "    #scaled_images  = normaliz_data2(np_data)\n",
    "    scaled_images  = np_data.reshape(-1, 30, 64, 64, 1)\n",
    "    return scaled_images\n",
    "\n",
    "#%%\n",
    "def normaliz_data2(v):\n",
    "    normalized_v = v / np.sqrt(np.sum(v**2))\n",
    "    return normalized_v\n",
    "\n",
    "\n",
    "class Conv3DModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Conv3DModel, self).__init__()\n",
    "        # Convolutions\n",
    "        self.conv1 = tf.compat.v2.keras.layers.Conv3D(32, (3, 3, 3), activation='relu', name=\"conv1\", data_format='channels_last')\n",
    "        self.pool1 = tf.keras.layers.MaxPool3D(pool_size=(2, 2, 2), data_format='channels_last')\n",
    "        self.conv2 = tf.compat.v2.keras.layers.Conv3D(64, (3, 3, 3), activation='relu', name=\"conv1\", data_format='channels_last')\n",
    "        self.pool2 = tf.keras.layers.MaxPool3D(pool_size=(2, 2,2), data_format='channels_last')\n",
    "\n",
    "        # LSTM & Flatten\n",
    "        self.convLSTM =tf.keras.layers.ConvLSTM2D(40, (3, 3))\n",
    "        self.flatten =  tf.keras.layers.Flatten(name=\"flatten\")\n",
    "\n",
    "        # Dense layers\n",
    "        self.d1 = tf.keras.layers.Dense(128, activation='relu', name=\"d1\")\n",
    "        self.out = tf.keras.layers.Dense(6, activation='softmax', name=\"output\")\n",
    "    \n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.convLSTM(x)\n",
    "        #x = self.pool2(x)\n",
    "        #x = self.conv3(x)\n",
    "        #x = self.pool3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.d1(x)\n",
    "        return self.out(x)\n",
    "#%%\n",
    "new_model = Conv3DModel()\n",
    "#%%\n",
    "new_model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer=tf.keras.optimizers.RMSprop())\n",
    "\n",
    "#%%\n",
    "new_model.load_weights('weights/3d-cnn-basic')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Conv3DModel.call of <__main__.Conv3DModel object at 0x7f2ac965edd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv3DModel.call of <__main__.Conv3DModel object at 0x7f2ac965edd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv3DModel.call of <__main__.Conv3DModel object at 0x7f2ac965edd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv3DModel.call of <__main__.Conv3DModel object at 0x7f2ac965edd0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "Classe =  Thumb Down Precision =  89.41754102706909 %\n",
      "Classe =  No gesture Precision =  98.72422218322754 %\n",
      "Classe =  Thumb Down Precision =  72.92562127113342 %\n",
      "Classe =  No gesture Precision =  71.40315771102905 %\n",
      "Classe =  Thumb Down Precision =  98.91197681427002 %\n",
      "Classe =  Thumb Down Precision =  45.70363163948059 %\n",
      "Classe =  No gesture Precision =  67.68810749053955 %\n",
      "Classe =  Thumb Down Precision =  99.60786700248718 %\n",
      "Classe =  Thumb Down Precision =  99.98388290405273 %\n",
      "Classe =  Thumb Down Precision =  91.49558544158936 %\n",
      "Classe =  Thumb Down Precision =  99.39570426940918 %\n",
      "Classe =  Thumb Down Precision =  97.72874116897583 %\n",
      "Classe =  Thumb Down Precision =  99.21748042106628 %\n",
      "Classe =  Thumb Down Precision =  99.97668862342834 %\n",
      "Classe =  Sliding Two Fingers Right Precision =  99.99070167541504 %\n",
      "Classe =  Sliding Two Fingers Left Precision =  69.6514368057251 %\n",
      "Classe =  Sliding Two Fingers Left Precision =  99.99980926513672 %\n",
      "Classe =  Sliding Two Fingers Left Precision =  99.00256395339966 %\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "to_predict = []\n",
    "num_frames = 0\n",
    "cap = cv2.VideoCapture(0)\n",
    "classe =''\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Our operations on the frame come here\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    to_predict.append(cv2.resize(gray, (64, 64)))\n",
    "    \n",
    "         \n",
    "    if len(to_predict) == 30:\n",
    "        frame_to_predict = np.array(to_predict, dtype=np.float32)\n",
    "        frame_to_predict = normaliz_data(frame_to_predict)\n",
    "        #print(frame_to_predict)\n",
    "        predict = new_model.predict(frame_to_predict)\n",
    "        classe = targets_dict[np.argmax(predict)]\n",
    "        \n",
    "        print('Classe = ',classe, 'Precision = ', np.amax(predict)*100,'%')\n",
    "\n",
    "\n",
    "        #print(frame_to_predict)\n",
    "        to_predict = []\n",
    "        #sleep(0.1) # Time in seconds\n",
    "        #font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(frame, classe, (30, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0),1,cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Hand Gesture Recognition',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is for saving weights does not store the defination of model \n",
    "# new_model.save_weights('./checkpoints/3dcnn-basic')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_model.save('jester_trained_models/3dcnn-hdf5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: jester_trained_models/3dcnn-basic/assets\n"
     ]
    }
   ],
   "source": [
    "new_model.save('jester_trained_models/3dcnn-basic', save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Optimizer arguments:\n",
      "Common parameters:\n",
      "\t- Path to the Input Model: \tNone\n",
      "\t- Path for generated IR: \t/home/deepanshu/open_vino/udacity_project_custom_model/\n",
      "\t- IR output name: \tsaved_model\n",
      "\t- Log level: \tERROR\n",
      "\t- Batch: \tNot specified, inherited from the model\n",
      "\t- Input layers: \tNot specified, inherited from the model\n",
      "\t- Output layers: \tNot specified, inherited from the model\n",
      "\t- Input shapes: \tNot specified, inherited from the model\n",
      "\t- Mean values: \tNot specified\n",
      "\t- Scale values: \tNot specified\n",
      "\t- Scale factor: \tNot specified\n",
      "\t- Precision of IR: \tFP32\n",
      "\t- Enable fusing: \tTrue\n",
      "\t- Enable grouped convolutions fusing: \tTrue\n",
      "\t- Move mean values to preprocess section: \tFalse\n",
      "\t- Reverse input channels: \tFalse\n",
      "TensorFlow specific parameters:\n",
      "\t- Input model in text protobuf format: \tFalse\n",
      "\t- Path to model dump for TensorBoard: \tNone\n",
      "\t- List of shared libraries with TensorFlow custom layers implementation: \tNone\n",
      "\t- Update the configuration file with input/output node names: \tNone\n",
      "\t- Use configuration file used to generate the model with Object Detection API: \tNone\n",
      "\t- Operations to offload: \tNone\n",
      "\t- Patterns to offload: \tNone\n",
      "\t- Use the config file: \tNone\n",
      "Model Optimizer version: \t2020.1.0-61-gd349c3ba4a\n",
      "[ ERROR ]  Unexpected exception happened during extracting attributes for node conv3d_model/conv_lst_m2d/bias/Read/ReadVariableOp.\n",
      "Original exception message: 'ascii' codec can't decode byte 0xc9 in position 1: ordinal not in range(128)\n"
     ]
    }
   ],
   "source": [
    "!python3 /opt/intel/openvino/deployment_tools/model_optimizer/mo_tf.py --saved_model_dir jester_trained_models/3dcnn-basic  --output_dir /home/deepanshu/open_vino/udacity_project_custom_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
